{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression\n",
    "\n",
    "\n",
    "This Jupyter notebook contains an outline of the theory behind the linear regression algorithm. Here we will discuss and implement the linear regression model using the traditional linear algebra approach. The idea is to understand the algorithm as a whole. \n",
    "\n",
    "Nowadays a resercher interested in implementing a linear regression model (or others) can make use of API's. All he/she has to do is to instantiate the desired object and use the methods to fit the data and make predictions. Although this is very convenient, the researcher might not understand what is going on inside the algorithm, what it is computing, or even find sources of errors. Even worse, the researcher might not understand the assumptions and limitations of the algorithm and could naively apply it to cases in which the assumptions are not valid. \n",
    "\n",
    "This humble step by step implementation forces the researcher to write and understand the code. It also forces him/her to check if the assumptions make sense. Only after the implementation is complete we will discuss the use of API's. Not always the programmer writes the fastest codes, and API's are in general efficient. But it is much better to lose a little of speed processing ang gain more certainty.\n",
    "\n",
    "### Disclaimer\n",
    "\n",
    "These codes are not meant to be fully original. Although some functions were created by me, others were inspired and adapted from different sources. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Assumptions of linear regression model\n",
    "\n",
    "There are two main assumptions in the linear regression model:\n",
    "\n",
    " **1. Linear dependence**: The dependent variable and the explanatory variables have a linear relationship. Before fitting the model the researcher must plot the dependent variable in terms of the explanatory variables in order to check if there is a visible linear relationship.\n",
    " \n",
    " \n",
    " **2. Normally distributed residuals**: The residuals must follow a normal distibution, so $E[u_i] = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Estimation techniques\n",
    "\n",
    "The most common estimations techniques are:\n",
    "\n",
    " **1. Ordinary Least Squares**\n",
    " \n",
    " \n",
    " **2. Variations of OLS**: Generalized Least Squares, Penalized Least Squares, i.e., L1 (LASSO) and L2 (Ridge)\n",
    " \n",
    "In this discussion we will implement only the Ordinary Least Squares estimation using matrices rules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory\n",
    "\n",
    "We will create our own class to fit a linear regression model. In matrix form, a linear regression model is expressed as\n",
    "\n",
    "$$\n",
    "y = X \\beta + u.\\tag{1}\n",
    "$$\n",
    "\n",
    "In terms of its components we have\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "y_1\\\\\n",
    "y_2\\\\\n",
    ":\\\\\n",
    "y_n\\\\\n",
    "\\end{bmatrix} = \n",
    "\\begin{bmatrix}\n",
    "1 & x_{11} & x_{12} & ... & x_{1K} \\\\\n",
    "1 & x_{21} & x_{22} & ... & x_{2K}\\\\\n",
    ": & : & : & : & :\\\\\n",
    "1 & x_{n1} & x_{n2} & ... & x_{nK}\\\\\n",
    "\\end{bmatrix}\n",
    "\\begin{bmatrix}\n",
    "\\beta_0\\\\\n",
    "\\beta_1\\\\\n",
    ":\\\\\n",
    "\\beta_K\\\\\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\begin{bmatrix}\n",
    "u_1\\\\\n",
    "u_2\\\\\n",
    ":\\\\\n",
    "u_n\\\\\n",
    "\\end{bmatrix}, \\tag{2}\n",
    "$$\n",
    "\n",
    "where $y$ is the dependent variable, $X$ is the feature matrix whose values are the independent variables $x_{ij}$, and the error term is $u = y - X\\beta$. Here, $\\beta$ is the vector whose values are the angular coefficients of the linear regression for each dimension. \n",
    "\n",
    "The regression line is the one that minimizes the sum of quadratic residuals, denoted by $SQR$, and given by\n",
    "\n",
    "$$\n",
    "SQR(\\beta) = u^{T}u = (y - X\\beta)^{T}(y - X\\beta)\\tag{3}.\n",
    "$$\n",
    "\n",
    "Some authors refer to this as $RSS$ for residual sum of squares, or $RSS$ for sum of squared residuals. We must find $\\beta$ so that $SQR$ is minimum. In order to do so, we take the first derivative with respect to $\\beta$, make the result equal to zero, use matrices rules, and finally compute the coefficients as\n",
    "\n",
    "$$\n",
    "\\beta = (X^{T}X)^{-1}X^{T}y. \\tag{4}\n",
    "$$\n",
    "\n",
    "Let us show how this result is obtained. In equation form $SQR$ is written as\n",
    "\n",
    "$$\n",
    "SQR(\\beta) = \\left(y_{1} - (\\beta_0 + \\beta_1 x_{11} + ... + \\beta_K x_{1K})\\right)^{2} + ... + \\left(y_{n} - (\\beta_0 + \\beta_1 x_{n1} + ... + \\beta_K x_{nK})\\right)^{2}. \\tag{5}\n",
    "$$\n",
    "\n",
    "Let us take the first derivative of this expression with respect to $\\beta_0$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial SQR(\\beta)}{\\partial \\beta_0} = 2\\left(y_{1} - (\\beta_0 + \\beta_1 x_{11} + ... + \\beta_K x_{1K})\\right)(-1) + ... + 2\\left(y_{n} - (\\beta_0 + \\beta_1 x_{n1} + ... + \\beta_K x_{nK})\\right)(-1). \\tag{6}\n",
    "$$\n",
    "\n",
    "We can group this expression in order to rewrite it in matrix form as\n",
    "\n",
    "$$\n",
    "\\frac{\\partial SQR(\\beta)}{\\partial \\beta_0} = -2[1 ... 1](y - X\\beta). \\tag{7}\n",
    "$$\n",
    "\n",
    "Now, let us take the first derivative with respect to $\\beta_1$:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial SQR(\\beta)}{\\partial \\beta_1} = 2\\left(y_{1} - (\\beta_0 + \\beta_1 x_{11} + ... + \\beta_K x_{1K})\\right)(-x_{11}) + ... + 2\\left(y_{n} - (\\beta_0 + \\beta_1 x_{n1} + ... + \\beta_K x_{nK})\\right)(-x_{n1}). \\tag{8}\n",
    "$$\n",
    "\n",
    "In matrix form we have\n",
    "\n",
    "$$\n",
    "\\frac{\\partial SQR(\\beta)}{\\partial \\beta_1} = -2[x_{11} ... x_{n1}](y - X\\beta). \\tag{9}\n",
    "$$\n",
    "\n",
    "We can easily generalize this computation and write the result in matrix form\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial SQR(\\beta)}{\\partial \\beta_0}\\\\\n",
    "\\frac{\\partial SQR(\\beta)}{\\partial \\beta_1}\\\\\n",
    ":\\\\\n",
    "\\frac{\\partial SQR(\\beta)}{\\partial \\beta_n}\\\\\n",
    "\\end{bmatrix} = -2\n",
    "\\begin{bmatrix}\n",
    "1 & 1 & 1 & ... & 1 \\\\\n",
    "x_{11} & x_{21} & x_{31} & ... & x_{n1}\\\\\n",
    ": & : & : & : & :\\\\\n",
    "x_{1K} & x_{2K} & x_{3K} & ... & x_{nK}\\\\\n",
    "\\end{bmatrix}\n",
    "(y - X\\beta) = -2X^{T}(y - X\\beta). \\tag{10}\n",
    "$$\n",
    "\n",
    "Now, we set this result to zero and this gives\n",
    "\n",
    "$$\n",
    "-2X^{T}(y - X\\beta) = 0\\\\\n",
    "-2X^{T}y+2X^{T}X\\beta = 0\\\\\n",
    "\\Rightarrow 2X^{T}X\\beta = 2X^{T}y \\\\\n",
    "\\Rightarrow \\beta = (X^{T}X)^{-1} X^{T}y \\tag{11}\n",
    "$$\n",
    "\n",
    "Now, we need to prove that the second derivatives are positive for these values of beta. Taking the second derivatives of $SQR$ we obtain \n",
    "\n",
    "$$\n",
    "\\frac{\\partial^{2} SQR(\\beta)}{\\partial \\beta_{0}^{2}} = 2(-1)(-1) + ... + 2(-1)(-1). \\tag{12}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{\\partial^{2} SQR(\\beta)}{\\partial \\beta_{1}^{2}} = 2(-x_{11})(-x_{11}) + ... + 2(-x_{n1})(-x_{n1}) = 2x_{11}^{2} + ... + 2x_{n1}^{2}. \\tag{13}\n",
    "$$\n",
    "\n",
    "We can generalize this result to obtain\n",
    "\n",
    "$$\n",
    "\\frac{\\partial^{2} SQR(\\beta)}{\\partial \\beta_{j}\\partial \\beta_{k}} = 2(x_{1j})(x_{1k}) + ... + 2(x_{nj})(x_{nk}). \\tag{14}\n",
    "$$\n",
    "\n",
    "This result is positive and independent of $\\beta$ which proves that $\\beta$ is the matrix of coefficients that minimize $SQR$. So, the straight line in the n-dimensional space whose coefficients are $\\beta$ represents our linear regression model!\n",
    "\n",
    "\n",
    "**A note about the intercept**: In order to include the intercept we must use the linear equation\n",
    "\n",
    "$$\n",
    "y = \\mathbb{1}\\beta_0 + X \\beta + u. \\tag{15}\n",
    "$$\n",
    "\n",
    "In general, we just input the matrix X and tell the code if we want a result that also fits the intercept, as we will do below.\n",
    "\n",
    "**A note about the gradient descent**: In general, matrix multiplication requires a lot of computing power. There is another way to estimate the vector $\\beta$ called the gradient descent method. This method will be discussed in a future opportunity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Coefficient of determination $R^2$: Goodness of a fit\n",
    "\n",
    "In order to determine how good our model fits the data we use the $R^2$ coefficient. It is given by the equation\n",
    "\n",
    "$$\n",
    "R^2=1-\\frac{\\text{SSE}}{\\text{SST}}, \\tag{16}\n",
    "$$\n",
    "\n",
    "where $\\text{SSE}=\\sum_{i=1}^{N}(y_{i}-\\hat{y}_{i})^{2}$ and $\\text{SST}=\\sum_{i=1}^{N}(y_{i}-\\bar{y})^{2}$. Notice that in the definition of $\\text{SST}$ we used the average of the data $\\bar{y}=(1/N)\\sum_{i=1}^{N}y_{i}$.\n",
    "\n",
    " - Case 1: $R^{2}=1$. This implies that our model has $\\text{SSE}=0$, which is a perfect fit with the data.\n",
    " - Case 2: $R^{2}=0$. This implies that our model has $\\text{SSE}=\\text{SST}$. This shows that our model is as good as a model whose regression line is actually the mean of all data points, i.e. $\\hat{y}=\\bar{y}$.\n",
    " - Case 1: $R^{2}<0$. This implies that our model is worse than the model whose regression line is the mean of all data points.\n",
    " \n",
    "In a good regression model $R^{2}\\rightarrow 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation\n",
    "\n",
    "The cross validation is a technique that splits the data into training set and test set. It is a good practice to choose the test set as a smaller percentage of the data. For the linear regression model, the training set corresponds to datapoints chosen randomly that will be used to fit the model. This means that the vector $\\beta$ will be determined using solely this set. After the algorithm learns what the vector $\\beta$ is during the training, we use the test set data to see if the model is making good predictions. The algorithm will use the function \"predict\", which accepts the features of the test data $X_\\text{test}$, and returns the predictions $\\hat{y}$. We then use a performance metrics to compare the predictions with the real values, i.e. $y_\\text{test}$. This will be of extreme importance in order to avoid overfitting problems. The most commonly used performance metrics for linear regression are discussed below.\n",
    "\n",
    "# Mean absolute error\n",
    "\n",
    "The mean absolute error is the averaged sum of the differences between the real values $y_{i}$ and the predicted values $\\hat{y}_{i}$. The closer the sum is to zero the better is the model. The formula is\n",
    "\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |y_{i} - \\hat{y}_{i}|. \\tag{17}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "# Root mean squared error\n",
    "The root mean squared error is the square root of the averaged sum of the squared differences between the real values $y_{i}$ and the predicted values $\\hat{y}_{i}$. Just like the $\\text{MAE}$, the closer it is to zero the better is the model. The formula is\n",
    "\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_{i} - \\hat{y}_{i})^{2}}. \\tag{18}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Linear Regression Class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We present the linear regression class below. Then we will show how each function works using simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression:\n",
    "    \"\"\"\n",
    "    Creates a model of the type linear regression\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, fit_intercept=True):\n",
    "        \"\"\"\n",
    "        Initialize the parameters\n",
    "        \"\"\"\n",
    "        self.fit_intercept = fit_intercept\n",
    "        self.beta = None\n",
    "        self.intercept_ = None\n",
    "        self.coef_ = None\n",
    "    \n",
    "    def _prepare_features(self, x):\n",
    "        \"\"\"\n",
    "        Stacks horizontaly an array of ones in order to compute the coefficients including the intercept\n",
    "        Final shape is (x.shape[0], x.shape[1]+1)\n",
    "        \n",
    "        Input:\n",
    "        x - features array of dimensions nxK\n",
    "        \n",
    "        Output:\n",
    "        x - transformed array of dimensions nx(K+1)\n",
    "        \"\"\"\n",
    "        if self.fit_intercept:\n",
    "            \n",
    "            if x.shape == (x.shape[0],):\n",
    "                x = x.reshape((x.shape[0],1))\n",
    "            \n",
    "            x = np.hstack((np.ones((x.shape[0], 1)), x))\n",
    "        return x\n",
    "    \n",
    "    def fit(self, x_train, y_train):\n",
    "        \"\"\"\n",
    "        Fits the linear model, i.e. computes the straight line coefficients\n",
    "        \n",
    "        Inputs:\n",
    "            x_train: array of dimensions nxK\n",
    "            y_train: array of dimensions nx1\n",
    "        \n",
    "        \"\"\"\n",
    "        x = self._prepare_features(x_train) \n",
    "        \n",
    "        # If fit_intercept true, returns coefficients with intercept. Else, returns coefficients without intercept\n",
    "        self.beta = self.least_squares(x, y_train)\n",
    "        \n",
    "        # Separates the intercept from coefficients if necessary\n",
    "        if self.fit_intercept:\n",
    "            self.intercept_ = self.beta[0]\n",
    "            self.coef_ = self.beta[1:]\n",
    "        else:\n",
    "            self.coef_ = self.beta\n",
    "        \n",
    "    def predict(self, x_test):\n",
    "        \"\"\"\n",
    "        This function takes the features array of the test set and returns, uses the coefficients computed by the fit\n",
    "        function, and then it computes the predictions, i.e. the y values of the regression line\n",
    "        \n",
    "        Inputs:\n",
    "            x_test: array of dimensions nxK\n",
    "\n",
    "        Output:\n",
    "        Predictions of the dependent variable\n",
    "        \"\"\"\n",
    "        x = self._prepare_features(x_test)\n",
    "        return np.dot(x , self.beta)\n",
    "    \n",
    "    def fit_predict(self, x, y):\n",
    "        \"\"\"\n",
    "        This function returns the regression line for the given features\n",
    "        \n",
    "        Input:\n",
    "        x: array - features array\n",
    "        y: array - dependent variable array\n",
    "        \n",
    "        Output:\n",
    "        Linear regression for the entire model\n",
    "        \n",
    "        \"\"\"\n",
    "        self.fit(x, y)\n",
    "        return self.predict(x)\n",
    "    \n",
    "    \n",
    "    if __name__ == \"__main__\":\n",
    "\n",
    "        def least_squares(self, x, y):\n",
    "            \"\"\"\n",
    "            Computes the parameters of the linear regression model that minimizes the sum of the squared distance between\n",
    "            the real value of the dependent variable and the value of the straight line that fits the model.\n",
    "\n",
    "            Inputs:\n",
    "            x: array of dimensions nxK\n",
    "            y: array of dimensions nx1\n",
    "\n",
    "            Output:\n",
    "            array of dimensions nx1\n",
    "            \"\"\"\n",
    "\n",
    "            return np.dot(np.linalg.inv(np.dot(x.T , x)) , np.dot(x.T , y))\n",
    "        \n",
    "    def r_squared(self, x, y):\n",
    "        \"\"\"\n",
    "        Computes the determination coefficient R^2 of the linear regression model\n",
    "        \n",
    "        Inputs:\n",
    "            x: array of dimensions nxK\n",
    "            y: array of dimensions nx1\n",
    "\n",
    "        Output:\n",
    "        coeff: float - value of R^2\n",
    "        \"\"\"\n",
    "        \n",
    "        # fits the model\n",
    "        self.fit(x, y)\n",
    "        \n",
    "        # computes the regression line\n",
    "        yhat = self.fit_predict(x, y)\n",
    "        \n",
    "        # computes the mean\n",
    "        mean = y.mean()\n",
    "        \n",
    "        # computes the coefficient of determination\n",
    "        R_squared = 1 - (np.dot((y-yhat).T, (y-yhat))/np.dot((y-mean).T, (y-mean)))\n",
    "        \n",
    "        return R_squared\n",
    "    \n",
    "    def mean_absolute_error(self, x_train, y_train, x_test, y_test):\n",
    "        \"\"\"\n",
    "        Computes the mean absolute error\n",
    "        \n",
    "        Inputs:\n",
    "            x_train: array of dimensions nxK\n",
    "            y_train: array of dimensions nx1\n",
    "            x_test: array of dimensions nxK\n",
    "            y_test: array of dimensions nx1\n",
    "\n",
    "        Output:\n",
    "        mae: float - value of the mean absolute error\n",
    "        \"\"\"\n",
    "        \n",
    "        # fits the model\n",
    "        self.fit(x_train, y_train)\n",
    "        \n",
    "        # computes the regression line\n",
    "        yhat = self.predict(x_test)\n",
    "        \n",
    "        # computes the mean absolute error\n",
    "        mae = (1/len(y_test))*np.sum(np.abs(yhat - y_test))\n",
    "        \n",
    "        return mae\n",
    "    \n",
    "    def root_mean_squared_error(self, x_train, y_train, x_test, y_test):\n",
    "        \"\"\"\n",
    "        Computes the root mean squared error\n",
    "        \n",
    "        Inputs:\n",
    "            x_train: array of dimensions nxK\n",
    "            y_train: array of dimensions nx1\n",
    "            x_test: array of dimensions nxK\n",
    "            y_test: array of dimensions nx1\n",
    "\n",
    "        Output:\n",
    "        mae: float - value of the mean absolute error\n",
    "        \"\"\"\n",
    "        \n",
    "        # fits the model\n",
    "        self.fit(x_train, y_train)\n",
    "        \n",
    "        # computes the regression line\n",
    "        yhat = self.predict(x_test)\n",
    "        \n",
    "        # computes the mean absolute error\n",
    "        rmse = ((1/len(y_test))*np.sum((yhat - y_test)**2))**0.5\n",
    "        \n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing with simulated data\n",
    "\n",
    "Consider the following simulated data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([2 + x + np.sin(x) for x in range(40)])\n",
    "x = np.array(list(range(40)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we can see that these points have an approximate linear dependence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1f41d535898>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us check whether our functions work and fit the data well. First, we create an instance and then fit the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = LinearRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us split the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x[:30]\n",
    "X_test = x[30:]\n",
    "y_train = y[:30]\n",
    "y_test = y[30:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function predict will give us the values of the vertical axis that will represent the straight line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = ex.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([31.98105079, 32.9771012 , 33.97315161, 34.96920202, 35.96525244,\n",
       "       36.96130285, 37.95735326, 38.95340367, 39.94945408, 40.9455045 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we plot both the data and the straight line. We can see that our model fits the data very well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f41d5b4208>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_test, y_test)\n",
    "plt.plot(X_test, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the $R^2$ factor close to one. In fact we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9935514577827103"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex.r_squared(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us compute the mean absolute error and the root mean squared error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE is  0.6823801233444566 .\n",
      "RMSE is  0.7324761547610115 .\n"
     ]
    }
   ],
   "source": [
    "print(\"MAE is \", ex.mean_absolute_error(X_train, y_train, X_test, y_test), \".\")\n",
    "\n",
    "print(\"RMSE is \", ex.root_mean_squared_error(X_train, y_train, X_test, y_test), \".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value must be compared to other linear regression models and the smallest one represent the best model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation with ScikitLearn\n",
    "\n",
    "Let us now compare our results with the ones we would obtain with scikitlearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#machine learing handle arrays\n",
    "X_sk_train = np.array(X_train).reshape(-1,1)\n",
    "y_sk_train = np.array(y_train).reshape(-1,1)\n",
    "X_sk_test = np.array(X_test).reshape(-1,1)\n",
    "y_sk_test = np.array(y_test).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we use Linear Regression + fit() is the training\n",
    "model_sk = LinearRegression()\n",
    "model_sk.fit(X_sk_train, y_sk_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sk_ypred = model_sk.predict(X_sk_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1f41ff3ee80>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_test, y_test)\n",
    "plt.plot(X_test, sk_ypred.reshape(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared value is 0.99355145778271 .\n",
      "MAE is 0.6823801233444563 .\n",
      "RMSE is 0.7324761547610105 .\n"
     ]
    }
   ],
   "source": [
    "#R value, MAE, and RMSE\n",
    "regression_model_mse = mean_squared_error(y_test, sk_ypred.reshape(len(y_test)))\n",
    "regression_model_mae = mean_absolute_error(y_test, sk_ypred.reshape(len(y_test)))\n",
    "print(\"R squared value is\", model_sk.score(X_sk_train,y_sk_train), \".\")\n",
    "print(\"MAE is\", regression_model_mae, \".\")\n",
    "print(\"RMSE is\", np.sqrt(regression_model_mse), \".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
